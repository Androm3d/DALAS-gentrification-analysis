%=====================================================
%   DALAS Project - Checkpoint 3: Data Assessment & Processing
%   FINAL, CORRECTED VERSION (FIXED PACKAGES)
%=====================================================

\documentclass[11pt,a4paper]{article}

%-----------------------------------
% PACKAGES (CORRECTED)
%-----------------------------------
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage[a4paper,margin=2.5cm]{geometry}
\usepackage{amsmath, amssymb, amsthm, mathtools} % Corrected: mathtools
\usepackage{physics}
\usepackage{bm}
\usepackage{siunitx} % Corrected: siunitx
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{float}
\usepackage{titlesec}
\usepackage[most]{tcolorbox}
\usepackage{minted}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{colortbl}
\usepackage{caption}
\usepackage{enumitem}
\usepackage{inconsolata}
\usepackage{longtable}
\usepackage{array}
\usepackage{url}

%-----------------------------------
% COLORS
%-----------------------------------
\definecolor{deepblue}{HTML}{1E3A8A}
\definecolor{deepgreen}{HTML}{065F46}
\definecolor{deepred}{HTML}{9B1C1C}
\definecolor{codegray}{gray}{0.95}
\definecolor{tablehead}{gray}{0.90}

%-----------------------------------
% PAGE STYLE
%-----------------------------------
\pagestyle{fancy}
\fancyhf{}
\lhead{\textbf{DALAS Project - Checkpoint 3}}
\rhead{\thepage}
\renewcommand{\headrulewidth}{0.4pt}
\setlength{\headheight}{14pt}

%-----------------------------------
% SECTION STYLING
%-----------------------------------
\titleformat{\section}{\normalfont\Large\bfseries\color{deepblue}}{}{0em}{}
\titleformat{\subsection}{\normalfont\large\bfseries\color{deepgreen}}{}{0em}{}

%-----------------------------------
% BOXES & COMMANDS
%-----------------------------------
\newtcolorbox{infobox}[1][]{colback=deepblue!5,colframe=deepblue!80!black, title=\textbf{Problem Recap},breakable,#1}
\newcommand{\code}[1]{\texttt{#1}}

%-----------------------------------
% REMOVE DEFAULT TITLE
%-----------------------------------
\title{}
\author{}
\date{}

%-----------------------------------
% DOCUMENT
%-----------------------------------
\begin{document}

%===================================
% NEW FULL-PAGE TITLE
%===================================
\begin{titlepage}
    \centering
    \vfill

    % University Logo
    \includegraphics[width=0.4\textwidth]{sorbonne-universite-sciences-logo-png_seeklogo-478816.jpg}
    \vspace{2cm}

    % Project Title
    {\Huge \bfseries Predicting the Next Wave of Gentrification\par}
    \vspace{1.5cm}

    % Subtitle
    {\Large \bfseries A Data-Driven Analysis and Forecasting Model\par}

    \vfill

    % Authors
    {\Large Gabriele Argentieri \& Marcel Alabart\par}
    \vspace{0.5cm}
    {\large \textit{DALAS - Sorbonne Université}\par}
    
    \vfill
    
    % Date
    {\large November 6, 2025\par}
    \vspace{1cm}

\end{titlepage}

%===================================
% REPORT CONTENT
%===================================
\pagestyle{fancy} % Reactivate fancy style for subsequent pages
\tableofcontents
\newpage

\section{Introduction and Problem Recap}

This report details the data assessment and processing phase of our project, which aims to identify the drivers of gentrification and predict future hotspots in Paris, Barcelona, and Milan. This phase is critical as it involves transforming a wide array of raw, heterogeneous data into a unified, analysis-ready dataset.

\begin{infobox}
    Our objective is to train a regression model to predict a "Gentrification Gap" index, defined for each neighborhood $i$ as:
    \[ G_i = \text{PercentileRank}(P_i) - \text{PercentileRank}(I_i) \]
    where $P_i$ is the median \textbf{price per square meter} and $I_i$ is the median household income. The feature importances derived from this model will allow us to understand the key drivers of this phenomenon.
\end{infobox}

\section{Data Processing and Integration Workflow}

To construct our master dataset, we executed a multi-stage workflow designed to handle the diverse formats and structures of our raw data sources. For each city, the process followed a consistent pattern, orchestrated using Python with the \code{pandas} and \code{geopandas} libraries.

\subsection{Step 1: Geospatial Foundation as a Spatial Index}
The first step was to establish a consistent geographical baseline for each city, serving as the spatial index for all subsequent data integration.
\begin{itemize}
    \item We obtained official boundary files for the administrative neighborhoods of Paris, Milan, and Barcelona. For Barcelona, this involved extracting the specific \textbf{`Barri`} layer from the official multi-layer \code{BCN\_UNITATS\_ADM.zip} shapefile.
    \item These files were loaded into a \code{geopandas} GeoDataFrame and re-projected to a common CRS (EPSG:4326), creating a "base layer" with a unique ID, name, and polygon \code{geometry} for each neighborhood.
\end{itemize}

\subsection{Step 2: Heterogeneous Data Sourcing}
Data acquisition required a multi-faceted approach, combining direct downloads from open data portals with targeted web scraping.
\begin{itemize}
    \item \textbf{Open Data Portals:} Socio-economic data for Barcelona, such as population demographics, income, and education levels, were sourced from the \textbf{Open Data BCN} portal. These datasets were provided at the fine-grained `Seccio_censal` (census tract) level, requiring subsequent aggregation.
    \item \textbf{Web Scraping for Market Data:} For market-driven data in Paris and Milan, we utilized a resilient web scraping pipeline to acquire real estate and tourism data. This involved using Selenium with human-like behavior simulation to navigate commercial platforms and retrieve point-based data (e.g., property listings).
    \item \textbf{Third-Party Data Aggregators:} Tourism pressure was measured using data from \textbf{Inside Airbnb}, which provides periodic snapshots of listings data for our target cities.
\end{itemize}

\subsection{Step 3: Source-Specific Processing and Spatial Joins}
Each raw dataset was independently cleaned, validated, and mapped to our geospatial base layer.
\begin{itemize}
    \item \textbf{Point-based Data (Real Estate, Tourism):} For scraped listings with latitude/longitude coordinates, we performed a \textbf{spatial join} (\code{gpd.sjoin}) to assign each point to its correct neighborhood polygon.
    \item \textbf{Area-based Data (Socio-Economic):} Official data, like Barcelona's census data, was provided with official neighborhood codes (`Codi_barri`). We performed extensive cleaning, such as parsing numeric values from object types and handling inconsistent column names, before aggregating the data from the census-tract level to the neighborhood level using the \code{median} to ensure robustness to outliers. This aggregated data was then joined to our base layer using a standard \code{pandas.merge}.
\end{itemize}

\subsection{Step 4: Final Merging and Master Dataset Creation}
With all data sources processed to the neighborhood level, we performed a final \textbf{inner join} on neighborhood ID and year. This crucial step ensures that our final master dataset contains only complete, consistent records for a defined analysis period, resolving issues of differing time coverages across datasets.

\section{The Master Data Schema}

The rigorous processing workflow resulted in the following unified data structure. Each row represents a single neighborhood in a given year, allowing for direct comparison across all three cities.

\begin{longtable}{>{\bfseries}p{0.2\textwidth} >{\raggedright\arraybackslash}p{0.3\textwidth} p{0.5\textwidth}}
\caption{Final Master Schema for the Analysis-Ready Dataset} \label{tab:schema} \\
\toprule
\rowcolor{tablehead}
\textbf{Category} & \textbf{Final Column Name} & \textbf{Description \& Justification} \\
\midrule
\endfirsthead
\multicolumn{3}{c}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\toprule
\rowcolor{tablehead}
\textbf{Category} & \textbf{Final Column Name} & \textbf{Description \& Justification} \\
\midrule
\endhead
\bottomrule
\endfoot
Identifiers & \verb|city| & The city name. Essential for comparative analysis. \\
& \verb|neighborhood_id| & A unique, standardized ID for each neighborhood. \\
& \verb|neighborhood_name| & The official name of the neighborhood. \\
& \verb|geometry| & The geographic polygon shape of the neighborhood. \\
\midrule
Target Variables & \verb|median_price_per_m2| & \textbf{Normalized price metric}. For Barcelona, this is the median cadastral value per m². For Milan/Paris, it's the median market price per m². Used to compute the target variable. \\
& \verb|median_household_income| & Median annual household income in euro. \\
& \verb|gentrification_gap_index| & \textbf{TARGET VARIABLE}. Calculated as \code{Rank(Price) - Rank(Income)}. \\
\midrule
Socio-Economic Features & \verb|population_density| & Inhabitants per km². Measures urban density. \\
& \verb|delta_population_density| & Percentage change in population density over the analysis period. \\
& \verb|pct_young_adults| & Percentage of population aged 25-39, a key gentrifier demographic. \\
& \verb|pct_higher_education| & Percentage of residents with a university degree. \\
& \verb|delta_higher_education| & Change in the percentage of residents with a university degree. \\
\midrule
Housing \& Tourism Features & \verb|airbnb_density| & Number of active Airbnb listings per 1,000 residents. \\
& \verb|pct_entire_home_airbnb| & Percentage of Airbnbs listed as "Entire home/apt," indicating commercial use. \\
\midrule
Urban Environment Features & \verb|is_in_renewal_zone| & A binary flag indicating if the neighborhood is in a designated urban renewal zone. \\
\bottomrule
\end{longtable}

\section{Current Data Assessment}
Our initial data exploration and validation have yielded the following key insights and resolutions:

\begin{itemize}
    \item \textbf{Data Comparability (Cadastral vs. Market):} Our most significant challenge is the use of different value types: official cadastral values for Barcelona and market values for Milan/Paris. We address this by: \textbf{(1)} Normalizing all price data to \textbf{price per square meter}, and \textbf{(2)} Using a \textbf{rank-based target variable}, which is robust to differences in absolute scales and focuses on the relative ordering of neighborhoods within each city.
    
    \item \textbf{Missing Values:} Differing time periods across raw datasets initially created many missing values. This was resolved by using an \textbf{inner merge} to define a core analysis period (e.g., 2018-2023) for which all key data points are available, resulting in a complete and consistent final dataset.

    \item \textbf{Outliers:} We detected outliers in population density and income, corresponding to real-world phenomena (e.g., industrial zones or extremely wealthy enclaves). By consistently using the \textbf{median} for aggregation and analysis, we have ensured our metrics are robust to these extreme values.

    \item \textbf{Bias:} We acknowledge two primary biases. \textbf{Source bias} exists as market data from portals may not capture all property sales. \textbf{Measurement bias} is inherent in our target variable, as the "Gentrification Gap" is a proxy for a complex social phenomenon. These limitations will be explicitly discussed in our final analysis.
\end{itemize}

\newpage
\section{Data Processing and Modeling Pipeline}
With a clean and validated master dataset, our project now enters the modeling phase. The following pipeline outlines our plan to move from data to actionable insights.

\begin{infobox}[title=Modeling Flight Plan]
    \textbf{Objective:} Predict the `gentrification_gap_index` at the end of our analysis period and identify the most important features driving the prediction.
\end{infobox}

\begin{enumerate}[leftmargin=*,label=\textbf{Step \arabic*:}]
    \item \textbf{Final Feature Engineering:}
    \begin{itemize}
        \item \textbf{Define Analysis Period:} We will establish a consistent analysis period across all cities based on our data availability, likely 2018 to 2023.
        \item \textbf{Create `delta_` Features:} We will calculate the percentage change for key time-varying features (e.g., `population_density`, `pct_higher_education`) between the start and end of this period.
        \item \textbf{Assemble Modeling Matrix:} We will create a final cross-sectional dataset where each row represents one neighborhood. The features (\textbf{X}) will be the socio-economic indicators from the start year (2018) plus the calculated `delta_` features. The target variable (\textbf{y}) will be the `gentrification_gap_index` from the end year (2023).
    \end{itemize}

    \item \textbf{Algorithm and Model Selection:}
    \begin{itemize}
        \item \textbf{Algorithm:} We have selected the \textbf{XGBoost Regressor} as our primary model. Its gradient boosting framework is highly effective for tabular data, robust to outliers, and ideal for capturing complex, non-linear interactions between urban features.
        \item \textbf{Task:} The problem is framed as a \textbf{regression task} to predict the continuous `gentrification_gap_index`.
    \end{itemize}
    
    \item \textbf{Data Preprocessing for Modeling:}
    \begin{itemize}
        \item \textbf{Data Splitting:} The combined dataset from all three cities will be split into an 80\% training set and a 20\% hold-out test set to ensure an unbiased evaluation of our final model.
        \item \textbf{Scaling:} Although XGBoost is insensitive to feature scaling, we will apply `StandardScaler` to the feature matrix as a best practice, facilitating potential comparisons with other models like regularized linear regression.
    \end{itemize}

    \item \textbf{Model Evaluation Metric:}
    \begin{itemize}
        \item \textbf{Metric:} Model performance will be assessed using \textbf{R-squared (R²)} on the test set. This metric will quantify the proportion of variance in the gentrification index that our model can explain, providing a clear measure of its predictive power. We will also report the \textbf{Mean Absolute Error (MAE)} to understand the average prediction error in terms of index points.
    \end{itemize}

    \item \textbf{Feature Importance Analysis:}
    \begin{itemize}
        \item \textbf{Methodology:} The core goal of our analysis is to identify the drivers of gentrification. Upon validating our model, we will use \textbf{SHAP (SHapley Additive exPlanations)} to interpret the trained XGBoost model.
        \item \textbf{Deliverable:} The SHAP analysis will produce summary plots ranking the features by their overall impact on the model's predictions. This will provide data-driven insights into which factors—tourism pressure, demographic shifts, or urban policy—are the most significant predictors of gentrification across our three European cities.
    \end{itemize}
\end{enumerate}

\end{document}